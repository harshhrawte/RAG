ğŸ¤– AlgoAssist: DSA RAG Chatbot
AlgoAssist is an intelligent Retrieval-Augmented Generation (RAG) chatbot designed to help students and developers learn and explore Data Structures and Algorithms (DSA). It uses a combination of LangChain, ChromaDB, LLaMA3, and Streamlit to provide accurate, context-aware answers extracted from a DSA book.

ğŸš€ Features
ğŸ“˜ PDF Knowledge Base: Ingests and indexes a DSA textbook using ChromaDB and sentence-transformer embeddings.

ğŸ” Retrieval-Augmented Generation: Retrieves relevant chunks before generating responses using LLaMA3.

ğŸ’¬ Natural Chat Interface: Built with Streamlit for an interactive and user-friendly experience.

âš™ï¸ Efficient Query Processing: Uses sentence-transformers for semantic search and LLaMA3-8B for generation.

ğŸ“ Project Structure

LLM-RAG/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ chatbot.py           # Core RAG logic
â”‚   â”œâ”€â”€ chroma_data.py       # Builds ChromaDB from PDF
â”‚   â”œâ”€â”€ llm.py               # Loads LLM, retriever, and prompt
â”œâ”€â”€ chroma_db/               # Persistent vector store
â”‚   â”œâ”€â”€ chroma.sqlite3
â”‚   â””â”€â”€ <auto-generated UUID folder>
â”œâ”€â”€ data/
â”‚   â””â”€â”€ DSA BOOK.pdf         # Source document (DSA book)
â”œâ”€â”€ interface/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ streamlit.py         # Streamlit frontend
â”œâ”€â”€ llm-rag-env/             # Your virtual environment (not version controlled)
â”œâ”€â”€ config.py                # API keys and constants
â”œâ”€â”€ requirements.txt         # Python dependencies
â”œâ”€â”€ run.sh                   # Shell script to start app
â”œâ”€â”€ Dockerfile               # Docker support
â”œâ”€â”€ .env                     # Environment variables (not version controlled)
â”œâ”€â”€ .gitignore
â”œâ”€â”€ .dockerignore
â””â”€â”€ README.md                # Project documentation

ğŸ› ï¸ Setup Instructions
1. Clone the Repository
 
git clone https://github.com/harshhrawte/LLM-RAG.git
cd LLM-RAG

2. Create a Virtual Environment

python -m venv env
source env/bin/activate   # On Windows: env\Scripts\activate

3. Install Dependencies

pip install -r requirements.txt

4. Set Up API Keys
Create a config.py file in the root directory with the following content:

GROQ_API_KEY = "your-groq-api-key"
HF_TOKEN = "your-huggingface-token"

âœ… Note: Youâ€™ll need a Groq API key and a HuggingFace token to use the LLaMA3 model and embeddings.

I have added the chroma_db as well so that bu just entering the api , one can directly run 

 streamlit run streamlit.py

 Visit http://localhost:8501 in your browser to start chatting with AlgoAssist!

 Some Screenshots of the output:

 